{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6a72d8-c7ab-4393-ad0d-9edc06159be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimon import Analyze, Application, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244a9542-8b05-440f-996d-4ef6919f6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"OPEN AI API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790a85fa-3026-4ea9-94e4-8bbb22cdb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_eval = Analyze(\n",
    "    Application(\"app_jun18_2024\"),\n",
    "    Model(\"my_gpt4_model_fine_tuned\", \"GPT-4\"), \n",
    "    api_key=\"AIMON_API_KEY\",\n",
    "    evaluation_name=\"simple_eval\",\n",
    "    dataset_collection_name=\"my_first_dataset_collection241\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c3e5f0-7611-4e44-ba32-b721fba56218",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_prod = Analyze(\n",
    "    Application(\"llm_marketing_summarization_app\"), \n",
    "    Model(\"my_gpt4_model_v2\", \"GPT-4\"), \n",
    "    api_key=\"AIMON_API_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a4ade-8083-4f67-a762-430f205c83b5",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We will run an evaluation the example below that uses Langchain to summarize documents using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af98abfc-c04d-4cc7-ba3c-62f550de0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanchain app example\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "@analyze_eval\n",
    "def run_application_eval_mode(source_text=None, prompt=None, user_query=None, eval_run=None):\n",
    "    # Split the source text\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    texts = text_splitter.split_text(source_text)\n",
    "    \n",
    "    # Create Document objects for the texts\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    \n",
    "    # Initialize the OpenAI module, load and run the summarize chain\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "    return chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdddfa8-43c7-446a-9337-3ad0f16a015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preetamjoshi/projects/aimon/pj_aimon_rely/examples/chbt/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/preetamjoshi/projects/aimon/pj_aimon_rely/examples/chbt/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' Acme recently launched version 2.1 of their Python library, which has deep integrations with the Python ecosystem and has been proven to be beneficial for developers. This new version includes features like async support and improved error handling.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " ('\\n\\nTo configure the Acme python client, follow the official documentation which includes setting up environment variables and installing dependencies for both basic and advanced setups.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " (' The Acme python client is compatible with Python 3.6+ and multiple databases, including MySQL, PostgreSQL, and MongoDB. It is also suitable for cross-language projects with Node.js.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " (' The Acme python client may have installation, package conflicts, and connectivity issues. Troubleshooting involves checking the Python environment, dependencies, and log files, with specific error resolutions available in the online help section.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " (' Acme recently launched version 2.1 of their Python library, which has deep integrations with the Python ecosystem and has been proven to be valuable for developers. This new version includes features like async support and improved error handling.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " ('\\n\\nTo configure the Acme python client, follow the official documentation which includes setting up environment variables and installing dependencies for both basic and advanced setups.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " (' The Acme python client is compatible with Python 3.6+ and multiple databases, including MySQL, PostgreSQL, and MongoDB. It is also suitable for cross-language projects with Node.js.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.')),\n",
       " (' The Acme python client may have installation, package conflicts, and connectivity issues. Troubleshooting involves checking the Python environment, dependencies, and log files, with specific error resolutions available in the online help section.',\n",
       "  AnalyzeCreateResponse(message='Data successfully sent to AIMon.'))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_application_eval_mode(None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ac734-ff30-4000-a410-65228e35fca8",
   "metadata": {},
   "source": [
    "### Production\n",
    "\n",
    "We will monitor the example below that uses Langchain to summarize documents using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44438e7f-5652-46b5-9244-cbf2977d9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanchain app example\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "@analyze_prod\n",
    "def run_application(source_text, prompt=None, user_query=None, eval_run=None):\n",
    "    # Split the source text\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    texts = text_splitter.split_text(source_text)\n",
    "    \n",
    "    # Create Document objects for the texts\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    \n",
    "    # Initialize the OpenAI module, load and run the summarize chain\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "    return chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb81a8ad-e10a-43f5-9682-844d9ab2ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"\"\"\n",
    "Large Language Models (LLMs) have become integral to automating and enhancing various business processes. \n",
    "However, a significant challenge these models face is the concept of \\\"hallucinations\\\" - outputs that, \n",
    "although fluent and confident, are factually incorrect or nonsensical. For enterprises relying on AI \n",
    "for decision-making, content creation, or customer service, these hallucinations can undermine credibility, \n",
    "spread misinformation, and disrupt operations. Recently, AirCanada lost a court case due to hallucinations \n",
    "in its chatbot [7]. Also, the 2024 Edelman Trust Barometer reported a drop in trust in AI companies from \n",
    "61% to 53% compared to 90% 8 years ago [8]. Recognizing the urgency of the issue, we have developed a \n",
    "state-of-the-art system designed for both offline and online detection of hallucinations, ensuring higher \n",
    "reliability and trustworthiness in LLM outputs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0dc9d7-e0b0-4a05-8967-0e06179486a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AnalyzeCreateResponse' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_application\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLanghchain based summarization of documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/aimon/pj_aimon_rely/aimon/decorators/analyze.py:118\u001b[0m, in \u001b[0;36mAnalyze.__call__.<locals>.wrapper\u001b[0;34m(context, sys_prompt, user_query, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval(func, args, kwargs)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Production mode, run the provided args through the user function\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_production_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/aimon/pj_aimon_rely/aimon/decorators/analyze.py:107\u001b[0m, in \u001b[0;36mAnalyze._run_production_analysis\u001b[0;34m(self, func, context, sys_prompt, user_query, args, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult must be returned by the decorated function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_am_app\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_am_app\u001b[38;5;241m.\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\n\u001b[1;32m    106\u001b[0m }\n\u001b[0;32m--> 107\u001b[0m aimon_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aimon_response, result\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AnalyzeCreateResponse' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "run_application(source_text, \"Langhchain based summarization of documents\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515eafd-8644-4792-a69e-23625a026c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
