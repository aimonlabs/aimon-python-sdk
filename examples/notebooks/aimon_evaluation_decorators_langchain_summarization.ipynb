{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8495fd8-cd0a-406f-8f20-f6b66fd585fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community langchain-openai tiktoken --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6a72d8-c7ab-4393-ad0d-9edc06159be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimon import AnalyzeEval, Application, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244a9542-8b05-440f-996d-4ef6919f6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7cf7522-c09c-4c4a-b714-f57527de6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "aimon_config = {\"hallucination\": {\"detector_name\": \"default\"},\n",
    "                \"conciseness\": {\"detector_name\": \"default\"},\n",
    "                \"completeness\": {\"detector_name\": \"default\"},\n",
    "                \"toxicity\": {\"detector_name\": \"default\"},\n",
    "                \"instruction_adherence\": {\"detector_name\": \"default\"}\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4afbd-afa2-402f-a63d-5121fe0385e2",
   "metadata": {},
   "source": [
    "### Create a dataset and a dataset collection\n",
    "\n",
    "AIMon can be used to manage datasets used for the evaluations. Here, we create two datasets and a collection\n",
    "comprising of these datasets. Note that these datasets only need to be created once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b73cf729-d349-4bbe-99bc-bbcfb8101bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Create a new datasets\n",
    "file_path1 = \"./test_evaluation_dataset_aug_2024_1.csv\"\n",
    "file_path2 = \"./test_evaluation_dataset_aug_2024_2.csv\"\n",
    "\n",
    "dataset_data_1 = json.dumps({\n",
    "    \"name\": \"test_evaluation_dataset_aug_2024_first.csv\",\n",
    "    \"description\": \"This is one custom dataset\"\n",
    "})\n",
    "\n",
    "dataset_data_2 = json.dumps({\n",
    "    \"name\": \"test_evaluation_dataset_aug_2024_second.csv\",\n",
    "    \"description\": \"This is another custom dataset\"\n",
    "})\n",
    "\n",
    "from aimon import Client\n",
    "aimon_api_key = os.getenv(\"AIMON_API_KEY\")\n",
    "aimon_client = Client(auth_header=f\"Bearer {aimon_api_key}\")\n",
    "\n",
    "with open(file_path1, 'rb') as file1:\n",
    "    dataset1 = aimon_client.datasets.create(\n",
    "        file=file1,\n",
    "        json_data=dataset_data_1\n",
    "    )\n",
    "\n",
    "with open(file_path2, 'rb') as file2:\n",
    "    dataset2 = aimon_client.datasets.create(\n",
    "        file=file2,\n",
    "        json_data=dataset_data_2\n",
    "    )\n",
    "dataset1 = aimon_client.datasets.list(name=\"test_evaluation_dataset_aug_2024_first.csv\")\n",
    "dataset2 = aimon_client.datasets.list(name=\"test_evaluation_dataset_aug_2024_second.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cc29c4-1cde-4b03-a489-7f055fedf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset collection\n",
    "dataset_collection = aimon_client.datasets.collection.create(\n",
    "    name=\"my_first_dataset_collection_aug_9_2024\", \n",
    "    dataset_ids=[dataset1.sha, dataset2.sha], \n",
    "    description=\"This is a collection of two datasets.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a4ade-8083-4f67-a762-430f205c83b5",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We will run an evaluation the example below that uses Langchain to summarize documents using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "790a85fa-3026-4ea9-94e4-8bbb22cdb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_eval = AnalyzeEval(\n",
    "    Application(\"llm_marketing_summarization_app_v3\"),\n",
    "    Model(\"my_gpt4_model_fine_tuned\", \"GPT-4\"), \n",
    "    headers=['context_docs', 'user_query', 'prompt', 'instructions'],\n",
    "    api_key=os.getenv(\"AIMON_API_KEY\"),\n",
    "    evaluation_name=\"simple_eval\",\n",
    "    dataset_collection_name=\"my_first_dataset_collection_aug_9_2024\",\n",
    "    config=aimon_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af98abfc-c04d-4cc7-ba3c-62f550de0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanchain app example\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "# eval = Eval(aimon_config)\n",
    "# eval.dataset_collection(data_coll_name)\n",
    "\n",
    "# The analyze_eval decorator will automatically stream through\n",
    "# records in the specified data collection and run it against \n",
    "# this function. The signature of this function should necessarily \n",
    "# contain context_docs, user_query and prompt as the first 3 \n",
    "# arguments. If you plan to provide \"instructions\" to compute the\n",
    "# instruction_adherence metric, make sure there is a 4th parameter \n",
    "# to this decorated function called \"instructions\".\n",
    "@analyze_eval\n",
    "def run_application_eval_mode(context_docs=None, user_query=None, prompt=None, instructions=None, my_arg=None):\n",
    "    # Split the source text\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    texts = text_splitter.split_text(context_docs)\n",
    "    \n",
    "    # Create Document objects for the texts\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    \n",
    "    # Initialize the OpenAI module, load and run the summarize chain\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "    return chain.run(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcdddfa8-43c7-446a-9337-3ad0f16a015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aimon_eval_res = run_application_eval_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6e94b08-0e2a-4860-a4f2-30d9ddea17af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Acme recently launched version 2.1 of their Python library, which has deep integrations with the Python ecosystem and has been proven to be valuable for developers. This new version includes features like async support and improved error handling. Acme also supports Javascript and Java.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), ('\\n\\nTo configure the Acme python client, follow the official documentation which includes setting up environment variables and installing dependencies for both basic and advanced setups.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), (' The Acme python client is compatible with Python 3.6+ and multiple databases, including MySQL, PostgreSQL, and MongoDB. It is also suitable for cross-language projects with Node.js.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), (' The Acme python client may have installation, package conflicts, and connectivity issues. Troubleshooting involves checking the Python environment, dependencies, and log files, with specific error resolutions available in the online help section.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), (' Acme recently launched version 2.1 of their Python library, which has deep integrations with the Python ecosystem and has been proven to be valuable for developers. This new version includes features like async support and improved error handling.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), ('\\n\\nTo configure the Acme python client, follow the official documentation which includes setting up environment variables and installing dependencies for both basic and advanced setups.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), (' The Acme python client is compatible with Python 3.6+ and multiple databases, including MySQL, PostgreSQL, and MongoDB. It is also suitable for cross-language projects with Node.js.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200)), (' The Acme python client may have installation, package conflicts, and connectivity issues. Troubleshooting involves checking the Python environment, dependencies, and log files, with specific error resolutions available in the online help section.', AnalyzeCreateResponse(message='Data successfully sent to AIMon.', status=200))]\n"
     ]
    }
   ],
   "source": [
    "print(aimon_eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4a272-428d-49d3-8f44-b92d82d36e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
