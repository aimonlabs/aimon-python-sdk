{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6a72d8-c7ab-4393-ad0d-9edc06159be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimon import Client, DatasetRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835191a-cb60-405f-8e89-57a7bfe02b9e",
   "metadata": {},
   "source": [
    "# Create an AIMon client\n",
    "\n",
    "This creates the AIMon client that will be used for the various different operations under evaluation and continuous monitoring of production applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790a85fa-3026-4ea9-94e4-8bbb22cdb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the AIMon client. You would need an API Key (that can be retrieved from the UI in your user profile). \n",
    "# Your user email is also needed to track ownership of components such as datasets and applications.\n",
    "aimon_client = Client(api_key=\"cfc819b4d923f5d86fb344655efac1cea0f0a247819716ad50c9b837fd188683\", email=\"preetam@aimon.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b7c9a-0001-4ada-8699-9350d27b735d",
   "metadata": {},
   "source": [
    "# Generative AI Model\n",
    "\n",
    "A model is a generative model that will be powering your application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90afb156-7538-4166-9c3b-0e5a131087dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4', 'Llama-2']\n"
     ]
    }
   ],
   "source": [
    "# Pick from existing model model types in the company. These are created by you or other member of your organization.\n",
    "# The AIMon client has a convenience function to easily retrieve this.\n",
    "list_model_types = aimon_client.list_model_types()\n",
    "print(list_model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808db089-f86e-4f79-9dc5-67e1a5fa35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the AIMon client, create or get a model for a given model type. \n",
    "# This API will automatically create a new model if it does not exist.\n",
    "my_model = aimon_client.model(\n",
    "    \"my_gpt4_model_fine_tuned\", \n",
    "    model_type=\"GPT-4\", \n",
    "    description=\"This model is a GPT4 based model and is fine tuned on the awesome_finetuning dataset\", \n",
    "    metadata={\"model_s3_location\":\"s3://bucket/key\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce5d51-4ceb-4a50-9561-681a1059076e",
   "metadata": {},
   "source": [
    "# LLM application\n",
    "\n",
    "This is to create or get an application that is using the above model. Each application is versioned i.e., each application is associated with a particular model for a given version of the application. When you use a different model for the same application, AIMon will automatically increment the version of the application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22794a7c-8193-4c10-b633-fe4d0d4277d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error, bad response: <Response [500]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maimon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApplicationStage\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Using the AIMon client, create or get an existing application\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m new_app \u001b[38;5;241m=\u001b[39m \u001b[43maimon_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplication\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_llm_summarization_app\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mApplicationStage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEVALUATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplicaiton_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://acme.com/summarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/aimon/aimon-rely/aimon/client.py:103\u001b[0m, in \u001b[0;36mClient.application\u001b[0;34m(self, name, model, stage, app_type, metadata)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m    102\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 103\u001b[0m application \u001b[38;5;241m=\u001b[39m \u001b[43mpost_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/v1/application\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAIMON_SDK_BACKEND_URL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m application:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError creating or retrieving the application with name \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, \u001b[38;5;28mtype\u001b[39m))\n",
      "File \u001b[0;32m~/projects/aimon/aimon-rely/aimon/utils/retry.py:36\u001b[0m, in \u001b[0;36mretry.<locals>.deco_retry.<locals>.f_retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_tries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exception_to_check \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_delay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/projects/aimon/aimon-rely/aimon/utils/http.py:28\u001b[0m, in \u001b[0;36mpost_request\u001b[0;34m(url, headers, data)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryableError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus code: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m received\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m201\u001b[39m]:\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError, bad response: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response))\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mException\u001b[0m: Error, bad response: <Response [500]>"
     ]
    }
   ],
   "source": [
    "from aimon import ApplicationStage\n",
    "# Using the AIMon client, create or get an existing application\n",
    "new_app = aimon_client.application(\n",
    "    \"my_llm_summarization_app\", \n",
    "    my_model, \n",
    "    stage=ApplicationStage.EVALUATION, \n",
    "    app_type=\"summarization\", \n",
    "    metadata={\"applicaiton_url\": \"https://acme.com/summarization\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a4ade-8083-4f67-a762-430f205c83b5",
   "metadata": {},
   "source": [
    "### Core LLM Application code\n",
    "\n",
    "The below example uses Langchain to do summarization of documents using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af98abfc-c04d-4cc7-ba3c-62f550de0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanchain app example\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "openai_api_key = \"YOUR API KEY HERE\"\n",
    "def run_application(source_text, prompt=None, user_query=None, eval_run=None):\n",
    "    # Split the source text\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    texts = text_splitter.split_text(source_text)\n",
    "    \n",
    "    # Create Document objects for the texts\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    \n",
    "    # Initialize the OpenAI module, load and run the summarize chain\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "    summary = chain.run(docs)\n",
    "    #print(\"Generated Summary: {}\".format(summary))\n",
    "\n",
    "    # Analyze quality of the generated output using AIMon\n",
    "    dr = DatasetRecord(prompt=prompt, user_query=user_query, context_docs=[d.page_content for d in docs])\n",
    "    res = aimon_client.analyze(new_app, dr, summary, eval_run)\n",
    "    print(\"Aimon response: {}\\n\".format(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b942b58-1d28-4efc-9aef-3e360740a6ca",
   "metadata": {},
   "source": [
    "# Evaluation of the LLM Application\n",
    "\n",
    "Before deploying the application to production, it is a good idea to test it end to end with either a curated golden dataset or a snapshot of production traffic. In this section, we will demonstrate how AIMon can assist you to perform these tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e362f3-7040-4648-8a07-991971c0705d",
   "metadata": {},
   "source": [
    "### Evaluation Dataset\n",
    "\n",
    "The dataset should be a CSV file with these columns: \n",
    " * \"prompt\": This is the prompt used for the LLM\n",
    " * \"user_query\": This the query specified by the user \n",
    "* \"context_docs\": These are context documents that are either retrieved from a RAG or through other methods. \n",
    "                  For tasks like summarization, these documents could be directly specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34881793-3778-4114-8066-7c41cfb6d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset\n",
    "# dataset1 = aimon_client.create_dataset(\"test_evaluation_dataset_1.csv\", \"./aimon_sdk_files/test_evaluation_dataset_1.csv\", \"This is one custom dataset\")\n",
    "# dataset2 = aimon_client.create_dataset(\"test_evaluation_dataset_2.csv\", \"./aimon_sdk_files/test_evaluation_dataset_2.csv\", \"This is another custom dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7cc2795-6010-479a-90c0-bd275589f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = aimon_client.get_dataset(\"test_evaluation_dataset_1.csv\")\n",
    "dataset2 = aimon_client.get_dataset(\"test_evaluation_dataset_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57718d53-ff05-40a2-ba35-db3964f868ee",
   "metadata": {},
   "source": [
    "### Dataset Collection\n",
    "\n",
    "You can define a collection of evaluation datasets for ease of use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbceabd-a6a2-4671-959d-ca15025841b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset collection\n",
    "dataset_collection = aimon_client.dataset_collection(\n",
    "    \"my_first_dataset_collection\", \n",
    "    [dataset1, dataset2], \n",
    "    \"This is a collection of two datasets.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72f64c-37c1-4500-b6c1-05793f03f66a",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "An evaluation is associated with a dataset collection and an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f7991bf-a7b5-42f6-9a45-08c66c98d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the AIMon client, create a new evaluation\n",
    "evaluation = aimon_client.evaluation(\"offline_evaluation_fine_tuned_model\", new_app, dataset_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea8115-192f-4bfd-a763-b1513c5ea7b9",
   "metadata": {},
   "source": [
    "### New Run\n",
    "A \"run\" is an instance of an evaluation that you would like to track metrics against. You could have multiple runs of the same evaluation. This is typically done is a CI/CD context where the same evaluation would run at regular intervals. Since LLMs are probabilitic in nature, they could produce different outputs for the same query and context. It is a good idea to run the evaluations regularly to understand the variations of outputs produced by your LLMs. In addition, runs give you the ability to choose different metrics for each run. \n",
    "\n",
    "Metrics are specified using the `metrics_config` parameter in the format shown below. The keys indicate the type of metric computed and the values are the specific algorithms used to compute those metrics. For most cases, we recommend using the `default` algorithm.\n",
    "\n",
    "Tags allow you to specify metadata like the application commit SHA or other key-value pairs that you want to insert for analytics purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b76a493-8738-40ba-a722-e22425c37e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the AIMon client, create a new evaluation run. \n",
    "eval_run = aimon_client.new_run(\n",
    "    evaluation, \n",
    "    metrics_config={'hallucination': 'default', 'toxicity': 'default', 'conciseness': 'default', 'completeness': 'default'},\n",
    "    tags={'application_commit_sha': '09395f57aac0769c55a0b3145b3f83e8ced148ef'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2706102-672d-4e11-b77b-c1110a31772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preetamjoshi/projects/aimon/aimon/datascience/aimon_dev/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/preetamjoshi/projects/aimon/aimon/datascience/aimon_dev/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n",
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the application on all the records in the dataset collection. \n",
    "for record in dataset_collection.records():\n",
    "    # Run the application code\n",
    "    run_application(record.context_docs, record.prompt, record.user_query, eval_run)\n",
    "\n",
    "# You can view metrics for your application on the UI: https://www.app.aimon.ai/llmapps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8070363-c9e3-497c-a0de-03b68bd9b49c",
   "metadata": {},
   "source": [
    "# Production\n",
    "\n",
    "Once you have built enough confidence through your evaluations of your application, you can deploy it to production. AIMon gives you the ability to continuously monitor your application for the configured metrics in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb81a8ad-e10a-43f5-9682-844d9ab2ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"\"\"\n",
    "Large Language Models (LLMs) have become integral to automating and enhancing various business processes. \n",
    "However, a significant challenge these models face is the concept of \\\"hallucinations\\\" - outputs that, \n",
    "although fluent and confident, are factually incorrect or nonsensical. For enterprises relying on AI \n",
    "for decision-making, content creation, or customer service, these hallucinations can undermine credibility, \n",
    "spread misinformation, and disrupt operations. Recently, AirCanada lost a court case due to hallucinations \n",
    "in its chatbot [7]. Also, the 2024 Edelman Trust Barometer reported a drop in trust in AI companies from \n",
    "61% to 53% compared to 90% 8 years ago [8]. Recognizing the urgency of the issue, we have developed a \n",
    "state-of-the-art system designed for both offline and online detection of hallucinations, ensuring higher \n",
    "reliability and trustworthiness in LLM outputs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e0dc9d7-e0b0-4a05-8967-0e06179486a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aimon response: {'message': 'Data successfully sent to AIMon.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_application(source_text, prompt=\"Langhchain based summarization of documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515eafd-8644-4792-a69e-23625a026c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
